{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150778a7",
   "metadata": {},
   "source": [
    "# Main Notebook\n",
    "\n",
    "The objective of this notebook is to retrieve reviews and papers from ICLR & NeurIps venues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661064b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb1b29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openreview\n",
    "import json\n",
    "import openreview.api as openreview_api\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Callable, Iterable, List, Dict, Optional\n",
    "import openreview.api as openreview_api\n",
    "\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35612b6",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75e0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any data type to json object\n",
    "def convert_2_json(item):\n",
    "    if hasattr(item, \"to_json\"):\n",
    "        payload = dict(item.to_json())\n",
    "        if getattr(item, \"details\", None) is not None:\n",
    "            payload[\"details\"] = item.details\n",
    "        return payload\n",
    "    if isinstance(item, list):\n",
    "        return [convert_2_json(x) for x in item]\n",
    "    if isinstance(item, dict):\n",
    "        return {k: convert_2_json(v) for k, v in item.items()}\n",
    "    return item\n",
    "\n",
    "# Save json file (convert to json format first if necessary)\n",
    "def save_json(data: Any, file_name: str, convert: bool = True) -> None:\n",
    "    serializable = convert_2_json(data) if convert else data\n",
    "    with open(f\"{file_name}.json\", \"w\") as fh:\n",
    "        json.dump(serializable, fh, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e852b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_markdown(pdf_url):\n",
    "    ''' \n",
    "        !!! This is a SAFTEY return, DO NOT Run this function\n",
    "        I REPEAT, DO NOT run this function on local \n",
    "    '''\n",
    "    from markitdown import MarkItDown\n",
    "    from io import BytesIO\n",
    "    import requests\n",
    "\n",
    "    # Get from URL \n",
    "    if not(pdf_url): return\n",
    "    response = requests.get(pdf_url)\n",
    "    pdf_bytes = response.content\n",
    "\n",
    "    md = MarkItDown()\n",
    "    result = md.convert(BytesIO(pdf_bytes), mime=\"application/pdf\")\n",
    "    if result and result.text_content:\n",
    "        return result.text_content\n",
    "    \n",
    "    with pymupdf.open(stream=pdf_bytes, filetype=\"pdf\") as doc:\n",
    "        return \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getAttr(paper,**attrs:str):\n",
    "    def go_deep(node,paths):\n",
    "        if not(node): return node\n",
    "        if len(paths) == 1:\n",
    "            return node.get(paths[0])\n",
    "        return go_deep(node.get(paths[0]), paths[1:])\n",
    "\n",
    "    results = {}\n",
    "    for key, values in attrs.items():\n",
    "        paths = values.split(\":\")\n",
    "        results[key] = go_deep(paper, paths)\n",
    "    return results\n",
    "def paperCleaner(paper, specialCase = '',doCleanString = True):\n",
    "    # Since some might have style in text \n",
    "    def cleanString(s):\n",
    "        return ''.join(c for c in s if c.isascii() and c != '\\n')\n",
    "\n",
    "    cp_paper = paper.copy()\n",
    "\n",
    "    # Reviews\n",
    "    reviews = []\n",
    "    decision = None\n",
    "    for reviewItem in paper.get(\"reviews\"):\n",
    "        ''' \n",
    "            Some have \"invitations\" and others have \"invitation\" \n",
    "            ==> make everything \"invitation\" for easier conditions\n",
    "        '''\n",
    "        puralVal = reviewItem.get(\"invitations\")\n",
    "        if puralVal: reviewItem[\"invitation\"] = puralVal\n",
    "\n",
    "        # Decisions\n",
    "        if not decision:\n",
    "            if specialCase == \"iclr_2019\":\n",
    "                decision = getAttr(reviewItem, decision = \"content:recommendation\")[\"decision\"]\n",
    "            elif specialCase in [\"iclr_2024\", \"iclr_2025\", \"neurips_2023\", \"neurips_2024\", \"neurips_2025\"]:\n",
    "                decision = getAttr(reviewItem, decision = \"content:decision:value\")[\"decision\"]\n",
    "            else:      \n",
    "                decision = getAttr(reviewItem, decision = \"content:decision\")[\"decision\"]\n",
    "        \n",
    "        # Reviews\n",
    "        if specialCase in [\"iclr_2024\", \"iclr_2025\", \"neurips_2023\", \"neurips_2024\", \"neurips_2025\"]:\n",
    "            if \"meta\" in \",\".join(i.lower() for i in reviewItem[\"invitation\"]):\n",
    "                continue\n",
    "            if \"review\" in \",\".join(i.lower() for i in reviewItem[\"invitation\"]):\n",
    "                \n",
    "                result = \"\\n\".join(\n",
    "                (\n",
    "                    # v is a list of objects\n",
    "                    f\"{k}:{cleanString(','.join(str(item['value']) for item in v))}\"\n",
    "                    if (doCleanString and isinstance(v, list))\n",
    "                    else f\"{k}:{', '.join(str(item['value']) for item in v)}\"\n",
    "                ) if isinstance(v, list)\n",
    "                else (\n",
    "                    # v is a single object\n",
    "                    f\"{k}:{cleanString(str(v['value']))}\"\n",
    "                    if doCleanString\n",
    "                    else f\"{k}:{str(v['value'])}\"\n",
    "                )\n",
    "                for k, v in reviewItem[\"content\"].items())\n",
    "                \n",
    "                date = reviewItem[\"cdate\"] if reviewItem.get(\"cdate\") else reviewItem.get(\"tcdate\")\n",
    "                reviewObj = {\"date\": date,\"review\": result}\n",
    "                reviews.append(reviewObj)\n",
    "\n",
    "        elif \"review\" in reviewItem[\"invitation\"].lower():\n",
    "            if specialCase in [\"iclr_2019\",\"neurips_2022\"] and (\"meta\" in reviewItem[\"invitation\"].lower()):\n",
    "                continue\n",
    "            result = \"\\n\".join(\n",
    "                f\"{k}:{cleanString(','.join(v)) if (doCleanString and isinstance(v, list)) else cleanString(v) if doCleanString else v}\"\n",
    "                for k, v in reviewItem[\"content\"].items()\n",
    "            )\n",
    "\n",
    "            date = reviewItem[\"cdate\"] if reviewItem.get(\"cdate\") else reviewItem.get(\"tcdate\")\n",
    "            reviewObj = {\"date\": date,\"review\": result}\n",
    "            reviews.append(reviewObj)\n",
    "        \n",
    "    del cp_paper[\"reviews\"]\n",
    "\n",
    "    cp_paper[\"reviews\"] = reviews\n",
    "    cp_paper[\"decision\"] = decision\n",
    "    cp_paper[\"has_revisions\"] = True if cp_paper[\"original_paper_id\"] else False\n",
    "    if cp_paper.get(\"pdf_url\"):\n",
    "        cp_paper[\"pdf_url\"] = \"https://openreview.net\" + cp_paper[\"pdf_url\"]\n",
    "    else:\n",
    "        cp_paper[\"pdf_url\"] = None\n",
    "    return cp_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f3a5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(directory_path):\n",
    "    # Check if directory exists\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"Error: '{directory_path}' is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Skip folders; only print files\n",
    "        if os.path.isfile(file_path):\n",
    "            size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "            # Convert to human-readable units\n",
    "            if size_bytes < 1024:\n",
    "                readable = f\"{size_bytes} B\"\n",
    "            elif size_bytes < (1024 ** 2):\n",
    "                readable = f\"{size_bytes / 1024:.2f} KB\"\n",
    "            elif size_bytes < (1024 ** 3):\n",
    "                readable = f\"{size_bytes / (1024 ** 2):.2f} MB\"\n",
    "            else:\n",
    "                readable = f\"{size_bytes / (1024 ** 3):.2f} GB\"\n",
    "\n",
    "            print(f\"{filename} — {readable}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "y1cksg8w7eg",
   "source": "def get_paper_url(paper_id: str, jsonl_file_path: str) -> Optional[str]:\n    \"\"\"\n    Retrieve the PDF URL for a paper given its ID from a JSONL file.\n    \n    Args:\n        paper_id: The paper ID to search for\n        jsonl_file_path: Path to the JSONL file containing paper data\n    \n    Returns:\n        The PDF URL if found, None otherwise\n    \"\"\"\n    try:\n        with open(jsonl_file_path, 'r') as f:\n            for line in f:\n                paper = json.loads(line.strip())\n                if paper.get('id') == paper_id:\n                    return paper.get('pdf_url')\n        return None\n    except FileNotFoundError:\n        print(f\"Error: File '{jsonl_file_path}' not found.\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Error: Failed to parse JSON - {e}\")\n        return None",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7f16a1ce",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba281b2c",
   "metadata": {},
   "source": [
    "### Retrieve Invitation URL of a conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fa3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openreview.Client(baseurl=\"https://api.openreview.net\") #v1\n",
    "# client = openreview_api.OpenReviewClient(baseurl=\"https://api2.openreview.net\")     #v2  \n",
    "# groups = client.get_groups(id=\"ICLR.cc/2021\")\n",
    "groups = client.get_all_groups(id=\"NeurIPS.cc/2023/Conference\")\n",
    "print(len(groups))\n",
    "print(groups[0])\n",
    "save_json(groups[0],\"playground_invitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a385d",
   "metadata": {},
   "source": [
    "### Retrieve Papers of a single Conference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 7396/7404 [00:17<00:00, 417.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "invitation_url = 'ICLR.cc/2024/Conference/-/Submission'\n",
    "# API 2\n",
    "client = openreview_api.OpenReviewClient(baseurl=\"https://api2.openreview.net\")\n",
    "notes = client.get_all_notes(invitation = invitation_url, details=\"directReplies,revisions\")\n",
    "if len(notes) == 0:\n",
    "    # API 1\n",
    "    client = openreview.Client(baseurl=\"https://api.openreview.net\")\n",
    "    notes = client.get_all_notes(invitation = invitation_url, details=\"directReplies,revisions\")\n",
    "\n",
    "print(len(notes))\n",
    "save_json(notes[50],\"playground_single_paper\")\n",
    "# save_json(notes[50],\"../raw out/NeurIPS_2025_paper_50_raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425d985",
   "metadata": {},
   "source": [
    "## Venue / paper Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = convert_2_json(notes)\n",
    "venue = \"iclr_2024\"\n",
    "index = 200\n",
    "\n",
    "# # iclr 2024\n",
    "if venue in [\"iclr_2024\",\"iclr_2025\",\"neurips_2023\",\"neurips_2024\",\"neurips_2025\"]:\n",
    "    new_paper = getAttr(papers[index], id = \"id\" , \n",
    "                    title = \"content:title:value\", pdf_url = \"content:pdf:value\", has_revisions= \"details:revisions\",\n",
    "                    authors = \"content:authors:value\", created_date = \"cdate\", original_paper_id = \"original\", \n",
    "                    reviews = \"details:directReplies\", invitation = \"invitations\"\n",
    "                    )\n",
    "else:\n",
    "    new_paper = getAttr(papers[index], id = \"id\" , \n",
    "                    title = \"content:title\" , pdf_url = \"content:pdf\", has_revisions= \"details:revisions\", \n",
    "                    authors = \"content:authors\", created_date = \"cdate\" , original_paper_id = \"original\",\n",
    "                    reviews = \"details:directReplies\", invitation = \"invitation\"\n",
    "                    )\n",
    "\n",
    "\n",
    "new_paper = paperCleaner(new_paper,venue)\n",
    "save_json(new_paper,\"new_paper\")\n",
    "get_pdf_markdown(new_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f80a6",
   "metadata": {},
   "source": [
    "## Final Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4fc94",
   "metadata": {},
   "source": [
    "_NOTE: The **ICLR 2016** is a workshop and **NeurIps 2019** is also considered as a workshop rather than conference_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fa454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Retriving papers from venue ICLR year 2016\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'R21' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R23' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R25' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R27' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R29' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R31' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R38' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R40' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R42' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R44' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R46' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R48' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R56' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R58' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R60' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R62' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R64' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R66' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R68' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R70' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R72' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R74' is an invalid float value\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "venue_invitations_url = {\n",
    "  'iclr_2016': 'ICLR.cc/2016/workshop/-/submission',\n",
    "  'iclr_2017': 'ICLR.cc/2017/conference/-/submission',\n",
    "  'iclr_2018': 'ICLR.cc/2018/Conference/-/Blind_Submission',\n",
    "  'iclr_2019': 'ICLR.cc/2019/Conference/-/Blind_Submission',\n",
    "  'iclr_2020': 'ICLR.cc/2020/Conference/-/Blind_Submission',\n",
    "  'iclr_2021': 'ICLR.cc/2021/Conference/-/Blind_Submission',\n",
    "  'iclr_2022': 'ICLR.cc/2022/Conference/-/Blind_Submission',\n",
    "  'iclr_2023': 'ICLR.cc/2023/Conference/-/Blind_Submission',\n",
    "  'iclr_2024': 'ICLR.cc/2024/Conference/-/Submission',\n",
    "  'iclr_2025': 'ICLR.cc/2025/Conference/-/Submission',\n",
    "  'neurips_2019': 'NeurIPS.cc/2019/Reproducibility_Challenge/-/Blind_Report',\n",
    "  'neurips_2021': 'NeurIPS.cc/2021/Conference/-/Blind_Submission',\n",
    "  'neurips_2022': 'NeurIPS.cc/2022/Conference/-/Blind_Submission',\n",
    "  'neurips_2023': 'NeurIPS.cc/2023/Conference/-/Submission',\n",
    "  'neurips_2024': 'NeurIPS.cc/2024/Conference/-/Submission',\n",
    "  'neurips_2025': 'NeurIPS.cc/2025/Conference/-/Submission'\n",
    "}\n",
    "if os.path.exists(\"notebook out\") and os.path.isdir(\"notebook out\"):\n",
    "    shutil.rmtree(\"notebook out\")\n",
    "os.makedirs(\"notebook out\")  \n",
    "  \n",
    "for venueName, invite_url in venue_invitations_url.items():\n",
    "    [venue_name , venue_year] = venueName.split(\"_\")\n",
    "    print(f\"> Retriving papers from venue {venue_name.upper()} year {venue_year}\")\n",
    "    # API 2\n",
    "    client = openreview_api.OpenReviewClient(baseurl=\"https://api2.openreview.net\")\n",
    "    notes = client.get_all_notes(invitation = invite_url, details=\"directReplies,revisions\")\n",
    "    if len(notes) == 0:\n",
    "        # API 1\n",
    "        client = openreview.Client(baseurl=\"https://api.openreview.net\")\n",
    "        notes = client.get_all_notes(invitation = invite_url, details=\"directReplies,revisions\")\n",
    "    save_json(notes[50],\"single_paper_raw\")\n",
    "    papers = convert_2_json(notes)\n",
    "\n",
    "    with open(f\"notebook out/{venueName.upper()}.jsonl\",\"w\") as f:\n",
    "      for i,paper in enumerate(papers):\n",
    "          if venueName in [\"iclr_2024\",\"iclr_2025\",\"neurips_2023\",\"neurips_2024\",\"neurips_2025\"]:\n",
    "            new_paper = getAttr(paper, id = \"id\" , \n",
    "                                title = \"content:title:value\", pdf_url = \"content:pdf:value\", has_revisions= \"details:revisions\",\n",
    "                                authors = \"content:authors:value\", created_date = \"cdate\", original_paper_id = \"original\", \n",
    "                                reviews = \"details:directReplies\", invitation = \"invitations\"\n",
    "                                )\n",
    "          else:\n",
    "            new_paper = getAttr(paper, id = \"id\" , \n",
    "                                title = \"content:title\" , pdf_url = \"content:pdf\", has_revisions= \"details:revisions\", \n",
    "                                authors = \"content:authors\", created_date = \"cdate\" , original_paper_id = \"original\",\n",
    "                                reviews = \"details:directReplies\", invitation = \"invitation\"\n",
    "                                )\n",
    "\n",
    "          new_paper = paperCleaner(new_paper,venueName)\n",
    "          print(i)\n",
    "          new_paper[\"pdf\"] = get_pdf_markdown(new_paper.get(\"pdf_url\"))\n",
    "          if i == 41: save_json(new_paper,\"single_paper_formatted\")\n",
    "          if i == 41: raise SystemExit\n",
    "          f.write(json.dumps(new_paper) + \"\\n\")\n",
    "print(\"---------------------\")\n",
    "print(\"\\n✓ All Jobs Done ✓\")\n",
    "print(\"=========== File Sizes Generated =========\")\n",
    "print_results(\"notebook out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}