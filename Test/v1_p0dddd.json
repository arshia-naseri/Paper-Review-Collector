{
    "id": "zzqBoIFOQ1",
    "original": "dC_9j4aLwcA",
    "cdate": 1663850184200,
    "pdate": 1675279800000,
    "odate": 1664468100000,
    "mdate": null,
    "tcdate": 1663850184200,
    "tmdate": 1760256707027,
    "ddate": null,
    "number": 3283,
    "content": {
        "title": "Guiding Safe Exploration with Weakest Preconditions",
        "authorids": [
            "~Greg_Anderson1",
            "~Swarat_Chaudhuri1",
            "~Isil_Dillig1"
        ],
        "authors": [
            "Greg Anderson",
            "Swarat Chaudhuri",
            "Isil Dillig"
        ],
        "keywords": [
            "reinforcement learning",
            "safe learning",
            "safe exploration"
        ],
        "TL;DR": "We use an online, weakest-precondition-based approach to ensure safety during exploration without interfering with performance.",
        "abstract": "In reinforcement learning for safety-critical settings, it is often desirable for the agent to obey safety constraints at all points in time, including during training. We present a novel neurosymbolic approach called SPICE to solve this safe exploration problem. SPICE uses an online shielding layer based on symbolic weakest preconditions to achieve a more precise safety analysis than existing tools without unduly impacting the training process. We evaluate the approach on a suite of continuous control benchmarks and show that it can achieve comparable performance to existing safe learning techniques while incurring fewer safety violations. Additionally, we present theoretical results showing that SPICE converges to the optimal safe policy under reasonable assumptions.",
        "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.",
        "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.",
        "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
        "submission_guidelines": "Yes",
        "resubmission": "",
        "student_author": "",
        "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)",
        "paperhash": "anderson|guiding_safe_exploration_with_weakest_preconditions",
        "pdf": "/pdf/31fba2ce53b7314f1c3b3ec7719c818d82414a6d.pdf",
        "supplementary_material": "/attachment/ec3f34f04957b594c28e243d8aa5403d15fd76b5.zip",
        "_bibtex": "@inproceedings{\nanderson2023guiding,\ntitle={Guiding Safe Exploration with Weakest Preconditions},\nauthor={Greg Anderson and Swarat Chaudhuri and Isil Dillig},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zzqBoIFOQ1}\n}",
        "venue": "ICLR 2023 poster",
        "venueid": "ICLR.cc/2023/Conference",
        "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/guiding-safe-exploration-with-weakest/code)"
    },
    "forum": "zzqBoIFOQ1",
    "referent": null,
    "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission",
    "replyto": null,
    "readers": [
        "everyone"
    ],
    "nonreaders": [],
    "signatures": [
        "ICLR.cc/2023/Conference"
    ],
    "writers": [
        "ICLR.cc/2023/Conference"
    ]
}