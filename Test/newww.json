{
    "id": "yqe0BZeN_xH",
    "original": "Kxuo8pMrNO",
    "cdate": 1663850583019,
    "pdate": 1675279800000,
    "odate": 1664468100000,
    "mdate": null,
    "tcdate": 1663850583019,
    "tmdate": 1676330777782,
    "ddate": null,
    "number": 6553,
    "content": {
        "title": "SwinZS3: Zero-Shot Semantic Segmentation with a Swin Transformer",
        "authorids": [
            "~Tian_YingJie1",
            "~Wang_YiQi1"
        ],
        "authors": [
            "Tian YingJie",
            "Wang YiQi"
        ],
        "keywords": [
            "zero shot semantic segmentation",
            "deep learning",
            "transformer"
        ],
        "abstract": "Zero-shot semantic segmentation (ZS3) aims at learning to classify the never-seen classes with zero training samples. Convolutional neural networks (CNNs) have recently achieved great success in this task. However, their limited attention ability constraints existing network architectures to reason based on word embeddings. In this light of the recent successes achieved by Swin Transformers, we propose SwinZS3, a new framework exploiting the visual embeddings and semantic embeddings on joint embedding space. The SwinZS3 combines a transformer image encoder with a language encoder. The image encoder is trained by pixel-text score maps using the dense language-guided semantic prototypes which are computed by the language encoder. This allows the SwinZS3 could recognize the unseen classes at test time without retraining. We experiment with our method on the  ZS3 standard benchmarks (PASCAL VOC and PASCAL Context) and the results demonstrate the effectiveness of our method by showing the state-of-art performance.",
        "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.",
        "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.",
        "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics",
        "submission_guidelines": "Yes",
        "resubmission": "",
        "student_author": "",
        "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning",
        "paperhash": "yingjie|swinzs3_zeroshot_semantic_segmentation_with_a_swin_transformer",
        "pdf": "/pdf/ffa678b1c4db0a5f11d4cb04680a118c0e187c41.pdf",
        "_bibtex": "@misc{\nyingjie2023swinzs,\ntitle={Swin{ZS}3: Zero-Shot Semantic Segmentation with a Swin Transformer},\nauthor={Tian YingJie and Wang YiQi},\nyear={2023},\nurl={https://openreview.net/forum?id=yqe0BZeN_xH}\n}",
        "supplementary_material": "/attachment/e9e2d3ca62ca498b20e0cca761a3b018393ecac7.zip",
        "venue": "Submitted to ICLR 2023",
        "venueid": "ICLR.cc/2023/Conference"
    },
    "forum": "yqe0BZeN_xH",
    "referent": null,
    "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission",
    "replyto": null,
    "readers": [
        "everyone"
    ],
    "nonreaders": [],
    "signatures": [
        "ICLR.cc/2023/Conference"
    ],
    "writers": [
        "ICLR.cc/2023/Conference"
    ],
    "details": {
        "directReplies": [
            {
                "id": "Gq-lGyVUipl",
                "original": null,
                "number": 1,
                "cdate": 1665914690410,
                "mdate": null,
                "ddate": null,
                "tcdate": 1665914690410,
                "tmdate": 1665914690410,
                "tddate": null,
                "forum": "yqe0BZeN_xH",
                "replyto": "yqe0BZeN_xH",
                "invitation": "ICLR.cc/2023/Conference/Paper6553/-/Official_Review",
                "content": {
                    "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
                    "summary_of_the_paper": "This paper proposes to tackle the problem of zero-shot semantic segmentation (ZS3). To capture the global feature relations and semantic information, SWIN transformer is adopted as the backbone. To improve the decision boundary, pixel-text auxiliary segmentation loss is used. Good benchmark results are obtained in Pascal VOC and Context datasets. ",
                    "strength_and_weaknesses": "Pros:\n1. The topic of zero-shot semantic segmentation is interesting and important. \n2. It achieves good benchmark results on Pascal VOC and Context datasets. (however the comparisons might be unfair, which will be described in Cons.)\n\n\nCons:\n1. The novelty of this paper is limited. It seems that the paper claims its novelty as using Swin Transformer, however, Swin Transformer has been widely used in CV community and simply adopts it as the backbone is not novel. In addition, the paper describes the cross-entropy loss, regression loss, semantic consistency loss in details. However, these techniques are proposed by JoEm (Baek et al. ICCV'2021). This paper simply uses them without any modifications. For L_aux, many papers have used similar losses. for example, Dong, Xiaoyi, et al. \"MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining.\" arXiv preprint arXiv:2208.12262 (2022)..\n \n2. The comparisons of the experiments (Table. 2) might be unfair. It uses stronger backbone (Swin Transformer) network compared to other methods. Please add experiments of DeepLabV3+ for all K in Table. 2. \n\n3. Please also discuss the relationship with CLIP-based zero-shot segmentation methods in the related work section. \n\n4. The paper writing needs significant improvement and careful revision. (1) The use of symbols is inconsistent. Does s in Eq.4 and Eq.6 the same? Some times N is used for the number of seen categories, sometimes K is used. (2) The introduction of \"regression loss\" is mostly unclear. where does semantic feature maps (s) come from? (3) The use of citation is wrong throughout the whole paper. (4) There are many typos. for example, extra \"()\" in Table. 2; \"deeplabv3+\" and \"Deeplabv3+\" in Table. 1. \n\nQuestions:\nThe paper writing is not clear enough. \n1. In Table.1, Does the 1st row (deeplabv3+) mean JoEm? \n",
                    "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality and originality of the paper is relatively poor. \nFor detailed explanation, please see Cons. above. ",
                    "summary_of_the_review": "Due to lack of novelty, unfair experimental comparisons, and poor paper writing, the reviewer suggests rejecting this paper in its current form. The paper needs major revision before resubmitting. ",
                    "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
                    "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
                    "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
                    "flag_for_ethics_review": [
                        "NO."
                    ],
                    "recommendation": "1: strong reject"
                },
                "signatures": [
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_nqEw"
                ],
                "readers": [
                    "everyone"
                ],
                "nonreaders": [],
                "writers": [
                    "ICLR.cc/2023/Conference",
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_nqEw"
                ]
            },
            {
                "id": "41SuloVWaIQ",
                "original": null,
                "number": 2,
                "cdate": 1666597281993,
                "mdate": null,
                "ddate": null,
                "tcdate": 1666597281993,
                "tmdate": 1670889305156,
                "tddate": null,
                "forum": "yqe0BZeN_xH",
                "replyto": "yqe0BZeN_xH",
                "invitation": "ICLR.cc/2023/Conference/Paper6553/-/Official_Review",
                "content": {
                    "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                    "summary_of_the_paper": "The article proposed a new network SwinZS3 that applies swin transformer to the zero-shot semantic segmentation domain. Experimental results on PASCAL VOC and PASCAL Context show that the method proposed in this paper outperforms existing methods.",
                    "strength_and_weaknesses": "Strength\n\n      -The proposed method achieved relatively good results on benchmarks.\n\n\nWeakness\n\n\n      -The presentation of some parts of the article is unclear. For example I'm confused about the structure of Language Encoder, but the article doesn't explain what it is throughout.\n      -There are many problems with the layout and writing of the article. For example, there is incorrect capitalization in the first line of section 3.1 and missing spaces in line 4. There is confusion about the case of symbols in section 3.4.\n     -Some recent related papers are not cited. Such as [1, 2, 3]\n    [1] https://arxiv.org/abs/2112.14757\n    [2] https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf\n    [3] https://arxiv.org/abs/2202.11094",
                    "clarity,_quality,_novelty_and_reproducibility": "The overall quality of the article is acceptable. The essay approach is slightly lacking in novelty. There are problems with the presentation and writing of the article. The reproducibility is okay if the code is released.",
                    "summary_of_the_review": "The method proposed in the article is not novel enough. In addition, there are major problems with the writing and layout of the article. I deem that it's not a solid work. So I tend to give weak reject.",
                    "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
                    "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
                    "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
                    "flag_for_ethics_review": [
                        "NO."
                    ],
                    "recommendation": "5: marginally below the acceptance threshold"
                },
                "signatures": [
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_S84P"
                ],
                "readers": [
                    "everyone"
                ],
                "nonreaders": [],
                "writers": [
                    "ICLR.cc/2023/Conference",
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_S84P"
                ]
            },
            {
                "id": "GVQab3adX0",
                "original": null,
                "number": 3,
                "cdate": 1666691009026,
                "mdate": null,
                "ddate": null,
                "tcdate": 1666691009026,
                "tmdate": 1666691009026,
                "tddate": null,
                "forum": "yqe0BZeN_xH",
                "replyto": "yqe0BZeN_xH",
                "invitation": "ICLR.cc/2023/Conference/Paper6553/-/Official_Review",
                "content": {
                    "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                    "summary_of_the_paper": "In this paper, the authors propose a discriminative zero-shot semantic segmentation approach that uses transformer image and language encoders to exploit the global relations of visual features and to reduce seen class bias. In this approach, the image encoder is trained with calculating pixel-text score maps which use dense language-guided semantic prototypes. The authors argue that CNN-based ZS3 models sometimes fail to extract language-guided activation fields because they work in reduced receptive fields and use fewer attention mechanisms to extract global relations. Experimental results on benchmark Pascal VOC and Pascal Context datasets show that this approach (i.e. SwinZS3) obtains state-of-the-art results.",
                    "strength_and_weaknesses": "Strengths:\n- The proposed transformer framework appears to be promising. The obtained limited experimental results (please see weaknesses) also support this situation.\n- Nice to see the impact of auxiliary segmentation loss on SwinZS3 and DeepLab methods.\nWeaknesses:\n- The text flow feels irregular. For example, CLIP-based meyhods are mentioned regardless of the context at the end of the Introduction section. Some figures are not referred from the text (eg, Fig.1 and Fig.4). Grammatical problems also disrupts the flow. In addition, the text contains too many typos; e.g. \"fro\", \"networkBaek\", \"generatining\", etc.\n- The authors follow the experimental settings provided by ZS3Net, and use 4 different splits for comparison with previous methods. However, there are 5 different splits according to the ZS3Net method and they share the results for 5 different splits in their paper. Hence, unseen-10 split results seem to be missing for both Pascal VOC and Pascal Context datasets.\n- When the results shared in Table 2 are examined, it is observed that the CSRL method generally obtains better results for the seen classes. However, there is no clear experimental result to support the central claim that the seen/unseen bias is alleviated via minimizing the euclidean distance and using the pixel-text score maps.\n\n*ZS3Net: Bucher, M., Vu, T. H., Cord, M., & P\u00e9rez, P. (2019). Zero-shot semantic segmentation. Advances in Neural Information Processing Systems",
                    "clarity,_quality,_novelty_and_reproducibility": "\nThe work has limited novelty: there are already uses of transformer models for semantic segmentation problems, the architecture change itself is not very interesting, and the other contributions are mainly adaptations of existing ZSL/semantic segmentation formulations. Due to the reasons mentioned above, the study includes various deficiencies in reproducibility.\n\nImportantly: it is not clear *how* the hyper-parameters were chosen. While several hyper-parameters are shared, it is not clear how they are tuned and whether unseen class samples (test examples) have been used in the process.",
                    "summary_of_the_review": "The arguments put forward by the authors are worth examining. (Limited) experiments also show that the method obtains successful results. However, the main and additional experiments are incomplete from my point of view. In addition, the study also needs serious improvements in writing, the overall manuscript quality does not meet the ICLR standards.",
                    "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
                    "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
                    "empirical_novelty_and_significance": "Not applicable",
                    "flag_for_ethics_review": [
                        "NO."
                    ],
                    "recommendation": "3: reject, not good enough"
                },
                "signatures": [
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_xJ8c"
                ],
                "readers": [
                    "everyone"
                ],
                "nonreaders": [],
                "writers": [
                    "ICLR.cc/2023/Conference",
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_xJ8c"
                ]
            },
            {
                "id": "hfCsbeSxed",
                "original": null,
                "number": 4,
                "cdate": 1666917393481,
                "mdate": null,
                "ddate": null,
                "tcdate": 1666917393481,
                "tmdate": 1670819442455,
                "tddate": null,
                "forum": "yqe0BZeN_xH",
                "replyto": "yqe0BZeN_xH",
                "invitation": "ICLR.cc/2023/Conference/Paper6553/-/Official_Review",
                "content": {
                    "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
                    "summary_of_the_paper": "The paper proposes a transformer based approach for zero shot semantic segmentation. It makes the use of different loss functions like cross entropy loss for seen classes, regression loss between language and visual features to account for unseen classes, a pixel text score map to reduce the seen bias problem and a semantic consistency loss to transfer the relationship of word2vec features to the semantic prototypes of the embedding space. State of the art results are shown on Pascal VOC and Context datasets.",
                    "strength_and_weaknesses": "The method obtains reasonable improvements over good baselines and state of the art results. \nThe use of pixel text score map is interesting. \n\n\nNo ablation experiments for Lsc and Lr, which are described as sub-sections of the technical contribution in the approach. \nThe paper is not written well and has several errors.",
                    "clarity,_quality,_novelty_and_reproducibility": "\n\n\nIntroduction: \nWSSS are often based on easily obtaining annotations, such as scribbles => sentence seems incorrect\n\nWe argue that a shared shortcoming of previous ZS3 models falls in the reduced receptive field of CNNs and less uses attention mechanisms for extracting the global relations of visual features conditioned with language semantic information. => 'less uses' does not seem right\n\nCurrent networkBaek et al. (2021) adopt traditional => space between network and Baek. Sentence also is not correct\n\nAlthough generative methods achieve impressive performance in zero-shot semantic segmentation tasks.The methods are limited by a multi-stage training strategy, Remove although or replace '.' with ','\n\nThe lsc is proposed by Baek et al. (2021), which define the relation between prototypes as follows: => language does not seem correct\n\nThe overall loss is finally formulated as\nL = Lce + Lr + \u03bb1Lsc + \u03bb2Laux, what is Laux in equation 2, I only see Lps in equation 2\n\n",
                    "summary_of_the_review": "The paper has many errors and has a few missing ablation experiments. The method does not seem very novel as it mixes a combination of loss functions (mostly known) with transformers to improve results marginally over baselines. Overall the contributions are borderline and near the acceptance threshold if some concerns are alleviated. \n\nUpdated rating after reading other reviews.",
                    "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
                    "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
                    "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
                    "flag_for_ethics_review": [
                        "NO."
                    ],
                    "recommendation": "5: marginally below the acceptance threshold"
                },
                "signatures": [
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_sxBw"
                ],
                "readers": [
                    "everyone"
                ],
                "nonreaders": [],
                "writers": [
                    "ICLR.cc/2023/Conference",
                    "ICLR.cc/2023/Conference/Paper6553/Reviewer_sxBw"
                ]
            },
            {
                "id": "h-cnXHk_Hsn",
                "original": null,
                "number": 1,
                "cdate": 1674241738797,
                "pdate": null,
                "mdate": null,
                "ddate": null,
                "tcdate": 1674241738797,
                "tmdate": 1674241738797,
                "tddate": null,
                "forum": "yqe0BZeN_xH",
                "replyto": "yqe0BZeN_xH",
                "invitation": "ICLR.cc/2023/Conference/Paper6553/-/Decision",
                "content": {
                    "title": "Paper Decision",
                    "decision": "Reject",
                    "metareview:_summary,_strengths_and_weaknesses": "The paper proposes a transformer-based approach for zero-shot semantic segmentation. To improve the decision boundary, pixel-text auxiliary segmentation loss is used and was shown to improve the performance. \n\nStrengths\n-------------\n\n\n- Reviewer sxBw, xJ8c,S84PJ,r nqEw: The method obtains reasonable improvements over good baselines and state-of-the-art results. Reviewer xJ8c: Nice to see the impact of auxiliary segmentation loss on SwinZS3 and DeepLab methods. \n- Reviewer xJ8c: The proposed transformer framework appears to be promising. \n- Reviewer nqEw: The topic of zero-shot semantic segmentation is interesting and important.\n\nWeaknesses\n-------------\n\n- Reviewer sxBw: No ablation experiments for Lsc and Lr, which are described as sub-sections of the technical contribution in the approach. \n- Reviewer sxBw, xJ8c, S84P, nqEw : The paper is not written well and has several grammatical errors. Detailed comments by reviewers clarify the details. \n- Reviewer xJ8c: there is no clear experimental result to support the central claim that the seen/unseen bias is alleviated via minimizing the euclidean distance and using the pixel-text score maps.\n- Reviewer xJ8c:  missing experiments for both Pascal VOC and Pascal Context datasets.\n-Reviewer nqEw : The novelty of this paper is limited. It seems that the paper claims its novelty as using Swin Transformer and compared to MaskCLIP paper (Dong, Xiaoyi, et al. \"). \n- The comparisons of the experiments (Table. 2) might be unfair. It uses a stronger backbone (Swin Transformer) network compared to other methods. Please add experiments of DeepLabV3+ for all K in Table. 2.\n- Missing discussion and experimental depth. \n\n\nIn conclusion, all reviewers are leaning towards not accepting the paper with its current version. \n\n",
                    "justification_for_why_not_higher_score": "Four knowledgeable reviewers recommend rejection. There is a rebuttal, and during the discussion, the reviewers reached a consensus that the paper has merits but is not ready for publication as there are several concerns in the paper's writings,  claims that lack sufficient support and design choices that lack sufficient justification, and missing experiments. The paper does not give a clear and strong intuition why the method work. No basis for overturning the reviews. ",
                    "justification_for_why_not_lower_score": "N/A.",
                    "summary_of_AC-reviewer_meeting": "N/A."
                },
                "signatures": [
                    "ICLR.cc/2023/Conference/Program_Chairs"
                ],
                "readers": [
                    "everyone"
                ],
                "nonreaders": [],
                "writers": [
                    "ICLR.cc/2023/Conference/Program_Chairs"
                ]
            }
        ]
    }
}